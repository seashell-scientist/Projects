unlist(lapply(num.nadata1, is.numeric))
numcolumns2
names(num.nadata1)
n <- names(num.nadata1)
n2
n[2]
n[18]
num.nadata1 <- num.nadata1[-18, ]
num.nadata1 <- num.nadata1[-18 ]
names(num.nadata1)
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[-18]
num.nadata1 <- num.nadata1[-5]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
names(num.nadata1)
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- num.nadata1[-7]
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[-18]
num.nadata1 <- num.nadata1[-5]
num.nadata1 <- num.nadata1[-7]
names(num.nadata1)
names(num.traindata)
num.nadata1 <- num.nadata1[-14]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
num.nadata1 <- nadata1
names(num.nadata1)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)]
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
knn1
summary(num.testdata)
num.testdata$Attrition = NA
num.testdata$Attrition
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
library(caTools)
#convert some to numeric to work with knn, remove others that don't translate well???
numcolumns <- unlist(lapply(maindata, is.numeric))
num.maindata <- maindata
num.maindata$Attrition <- as.numeric(num.maindata$Attrition)
num.maindata$BusinessTravel <- as.numeric(num.maindata$BusinessTravel)
num.maindata$Gender <- as.numeric(num.maindata$Gender)
num.maindata$Over18 <- as.numeric(num.maindata$Over18)
num.maindata$OverTime <- as.numeric(num.maindata$OverTime)
numcolumns2 <- unlist(lapply(num.maindata, is.numeric)) #should only be 4 variables that won't translate well to numeric
#remove department, education field, jobrole, and marital status
num.maindata <- num.maindata[, numcolumns2 ] #should trim 36 vars down to 32
set.seed(858) #same set as the NB, for comparison's sake
sampleset = sample.split(num.maindata, SplitRatio = 0.7)
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
names(num.traindata)
library(tibble)
add_column(num.nadata1, Attrition = 1, .after = "Age")
typeof(num.nadata1)
typeof(as.data.frame(num.nadata1))
library(tibble)
add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
num.traindata
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
library(tibble)
add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
NROW(num.traindata)
NROW(num.nadata1)
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
library(tibble)
add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
knn2 <- knn(train = num.traindata, test = as.list(num.nadata1), cl = num.training.definition,  k = 29)
NROW(as.list(num.nadata1))
as.list(num.nadata1)
add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
library(tibble)
num.nadata1 <- add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
library(tibble)
num.nadata1 <- add_column(as.data.frame(num.nadata1), Attrition = 1, .after = "Age")
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
knn2
summary(knn2)
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.test.definition,  k = 29)
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.testing.definition,  k = 29)
NROW(num.nadata1)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
num.nadata1 <- nadata1
num.nadata1 <- lapply(num.nadata1, as.numeric)
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.testing.definition,  k = 29)
num.nadata1 <- nadata1
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.testing.definition,  k = 29)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16)] #remove the same vars
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.testing.definition,  k = 29)
NROW(num.traindata)
NROW(num.traindata)
NROW(num.testdata)
NROW(num.training.definition)
NROW(num.testing.definition)
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
num.nadata1 <- nadata1
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- lapply(num.nadata1, as.numeric)
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16)] #remove the same vars
num.nadata1 <- lapply(num.nadata1, as.numeric)
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -18)] #remove the same vars
num.nadata1 <- lapply(num.nadata1, as.numeric)
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
typeof(num.traindata)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
summary(knn2)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
summary(knn2)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -18, -16)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
summary(knn2)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
names(num.traindata)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
num.traindata <- num.traindata[-3]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 29)
summary(knn2)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
num.traindata <- num.traindata[-3]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 2)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
library(caTools)
#convert some to numeric to work with knn, remove others that don't translate well???
numcolumns <- unlist(lapply(maindata, is.numeric))
num.maindata <- maindata
num.maindata$Attrition <- as.numeric(num.maindata$Attrition)
num.maindata$BusinessTravel <- as.numeric(num.maindata$BusinessTravel)
num.maindata$Gender <- as.numeric(num.maindata$Gender)
num.maindata$Over18 <- as.numeric(num.maindata$Over18)
num.maindata$OverTime <- as.numeric(num.maindata$OverTime)
numcolumns2 <- unlist(lapply(num.maindata, is.numeric)) #should only be 4 variables that won't translate well to numeric
#remove department, education field, jobrole, and marital status
num.maindata <- num.maindata[, numcolumns2 ] #should trim 36 vars down to 32
set.seed(858) #same set as the NB, for comparison's sake
sampleset = sample.split(num.maindata, SplitRatio = 0.7)
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
num.traindata = num.traindata[-3]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 2)
num.training.definition
library(caTools)
#convert some to numeric to work with knn, remove others that don't translate well???
numcolumns <- unlist(lapply(maindata, is.numeric))
num.maindata <- maindata
num.maindata$Attrition <- as.numeric(num.maindata$Attrition)
num.maindata$BusinessTravel <- as.numeric(num.maindata$BusinessTravel)
num.maindata$Gender <- as.numeric(num.maindata$Gender)
num.maindata$Over18 <- as.numeric(num.maindata$Over18)
num.maindata$OverTime <- as.numeric(num.maindata$OverTime)
numcolumns2 <- unlist(lapply(num.maindata, is.numeric)) #should only be 4 variables that won't translate well to numeric
#remove department, education field, jobrole, and marital status
num.maindata <- num.maindata[, numcolumns2 ] #should trim 36 vars down to 32
set.seed(858) #same set as the NB, for comparison's sake
sampleset = sample.split(num.maindata, SplitRatio = 0.7)
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
num.traindata = num.traindata[-3]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 2)
summary(knn2)
knnpredictions <- data.frame(nadata1$ID, knn2)
View(knnpredictions)
View(nbpredictions1)
names(knnpredictions) <- c("ID", "Predicted Attrition")
knnpredictions <- data.frame(nadata1$ID, knn2)
knnpredictions$knn2 <- ifelse(knnpredictions$knn2 == 1, "no", "yes")
View(knnpredictions)
names(knnpredictions) <- c("ID", "Predicted_Attrition")
write.csv(knnpredictions1, file = "KNN_Predicted_Attrition.csv")
write.csv(knnpredictions, file = "KNN_Predicted_Attrition.csv")
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
library(caTools)
#convert some to numeric to work with knn, remove others that don't translate well???
numcolumns <- unlist(lapply(maindata, is.numeric))
num.maindata <- maindata
num.maindata$Attrition <- as.numeric(num.maindata$Attrition)
num.maindata$BusinessTravel <- as.numeric(num.maindata$BusinessTravel)
num.maindata$Gender <- as.numeric(num.maindata$Gender)
num.maindata$Over18 <- as.numeric(num.maindata$Over18)
num.maindata$OverTime <- as.numeric(num.maindata$OverTime)
numcolumns2 <- unlist(lapply(num.maindata, is.numeric)) #should only be 4 variables that won't translate well to numeric
#remove department, education field, jobrole, and marital status
num.maindata <- num.maindata[, numcolumns2 ] #should trim 36 vars down to 32
set.seed(858) #same set as the NB, for comparison's sake
sampleset = sample.split(num.maindata, SplitRatio = 0.7)
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 2)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 3)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 29)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
kvalue = seq(1:100)
kacc <- vector()
kvar = 1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kvar = kvar +1
kacc <- cbind(kacc, 1)
kacc <- cbind(kacc, 1)
kacc <- cbind(kacc, 1)
kacc <- cbind(kacc, 1)
kacc <- cbind(kacc, 1)
kacc <- cbind(kacc, 1)
kvalue = seq(1:100) #iterate accuracy through many kvalues
kacc <- vector() #holds acc values
kvar = 1 #counter
kvalue = seq(1:100) #iterate accuracy through many kvalues
kacc <- vector() #holds acc values
kvar = 1 #counter
for(i in kvalue)
{
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = kvar)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
kacc <- cbind(kacc, ktest.acc)
kvar = kvar+1
}
library(ggplot2)
ggplot(traindata, aes(x = YearsAtCompany, fill = Attrition)) +
geom_bar(aes(y = (..count..)/sum(..count..)), alpha = 0.5) +
ylab("% ?") +
labs(title="Years Employed",x="Years",y="Attrition Rate")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
#lab techs, research sci, sales exec, and sales rep have higher attrition rates than the rest?
library(ggplot2)
ggplot(aes(x = kvalue, y = kacc)) +
geom_smooth() +
labs(title="Model Accuracy vs K-Value",x="K-Value",y="Model Accuracy")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
kvalue = seq(1:100) #iterate accuracy through many kvalues
kacc <- vector() #holds acc values
kvar = 1 #counter
for(i in kvalue)
{
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = kvar)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
kacc <- cbind(kacc, ktest.acc)
kvar = kvar+1
}
kopt <- data.frame(kvalue, kacc)
View(kopt)
View(kacc)
typeof(kacc)
typeof(kvalue)
kopt = as.data.frame(kvalue, kacc)
kopt = data.frame(kvalue, kacc)
kopt = data.frame(kvalue, kvalue)
View(kopt)
kacc <- vector() #holds acc values
kacc <- cbind(2)
kacc
kacc <- cbind(2)
kacc
kacc <- cbind(kacc, 2)
kacc
kacc <- cbind(kacc, 2)
kacc
kacc <- vector()
kacc <- c(kacc, 2)
kacc <- c(kacc, 2)
kacc <- c(kacc, 2)
kacc <- c(kacc, 2)
kacc <- c(kacc, 2)
kvalue = seq(1:100) #iterate accuracy through many kvalues
kacc <- vector() #holds acc values
kvar = 1 #counter
for(i in kvalue)
{
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = kvar)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
kacc <- c(kacc, ktest.acc)
kvar = kvar+1
}
kopt = data.frame(kvalue, kacc)
library(ggplot2)
ggplot(kopt, aes(x = kvalue, y = kacc)) +
geom_smooth() +
labs(title="Model Accuracy vs K-Value",x="K-Value",y="Model Accuracy")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
kvalue = seq(1:50) #iterate accuracy through many kvalues
kacc <- vector() #holds acc values
kvar = 1 #counter
for(i in kvalue)
{
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = kvar)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
kacc <- c(kacc, ktest.acc)
kvar = kvar+1
}
kopt = data.frame(kvalue, kacc)
library(ggplot2)
ggplot(kopt, aes(x = kvalue, y = kacc)) +
geom_smooth() +
labs(title="Model Accuracy vs K-Value",x="K-Value",y="Model Accuracy")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 15)
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
num.nadata1 <- nadata1
#num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same 4 vars
num.nadata1 <- num.nadata1[c(-5, -8, -16, -18)] #remove the same vars
num.nadata1 <- as.data.frame(lapply(num.nadata1, as.numeric))
num.traindata = num.traindata[-3]
knn2 <- knn(train = num.traindata, test = num.nadata1, cl = num.training.definition,  k = 15) #generate predictions from nadata
summary(knn2)
knnpredictions <- data.frame(nadata1$ID, knn2)#match predictions to nadata1 ID
knnpredictions$knn2 <- ifelse(knnpredictions$knn2 == 1, "no", "yes") #shift binary guess to yes and no
names(knnpredictions) <- c("ID", "PredictedAttrition")
write.csv(knnpredictions, file = "KNN_Predicted_Attrition.csv")
knnpred_caret <- train(num.traindata, num.testdata, method = "knn", preProcess = c("center","scale"))
knnpred_caret <- knn(num.traindata, num.testdata, method = "knn", preProcess = c("center","scale"))
?confusionMatrix
library(caret)
library(caret)
confusionMatrix(knn1, num.training.definition)
n = 100 #number of different split sets to process
m = seq(n)
for(i in m)
{
sampleset = sample.split(num.maindata, SplitRatio = 0.7) #iterate through different splits
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 15) #taken from kvalue optimization
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
}
n = 100 #number of different split sets to process
m = seq(n)
ka.list <- vector()
for(i in m)
{
sampleset = sample.split(num.maindata, SplitRatio = 0.7) #iterate through different splits
num.traindata <- subset(num.maindata, sampleset == TRUE)
num.testdata = subset(num.maindata, sampleset == FALSE)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 15) #taken from kvalue optimization
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ka.list <- c(ka.list, ktest.acc)
}
mean(ka.list)
ka.mean <- mean(ka.list)
sprintf("Mean KNN Training Set Accuracy = %f", ka.mean <- mean(ka.list))
ka.mean <- mean(ka.list)
sprintf("Splits Tested = %i", n)
sprintf("Mean KNN Training Set Accuracy = %f", ka.mean <- mean(ka.list))
NROW(num.training.definition)
NROW(knn1)
NROW(num.testing.definition)
library(caret)
confusionMatrix(knn1, num.testing.definition)
summary(knn1)
summary(num.testing.definition)
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 15) #taken from kvalue optimization
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
library(caret)
confusionMatrix(knn1, as.factor(num.testing.definition))
library(class)
num.training.definition <- num.traindata$Attrition #values to check knn guesses against? or ID?
num.testing.definition <- num.testdata$Attrition
knn1 <- knn(train = num.traindata, test = num.testdata, cl = num.training.definition,  k = 15) #taken from kvalue optimization
ktest.acc <- sum(num.testing.definition == knn1)/NROW(num.testing.definition)
ktest.acc
tt.predictions(nb.class2)
predictions1 <-  tt.predictions(nb.class2)
predictions1$train.table
predictions1$test.table
predictions1$train.accuracy
predictions1$test.accuracy
?confusionMatrix
summary(nb.class2)
nb.class2
library(caret)
#reminder, sensitivity is the rate of correct "positive" guesses
#specificity is the rate of correct "negative" classifications/guesses
confusionMatrix(predictions1$train.predictions, traindata$Attrition)
